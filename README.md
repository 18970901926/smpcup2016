数据预处理： 读取数据，过滤停用词

特征工程：     
1.基本特征，提取用户的姓名长度, 缺失值数量，粉丝数量，微博数量，平均每条微博的评论/转发人数，以及它们的排序特征，最大/最小的评论/转发数，姓名/图片/粉丝/转发/评论是否缺失，搭建省份-地区映射表，对博文中出现的省份进行匹配，并映射成地区，统计博文中出现的地区数量。

2.word2vec特征，训练word2vec词向量，统计每个用户的平均向量(对所有博文求平均向量)，再利用word2vec得出的用户平均向量进行xgboost训练并预测出每个用户属于某个类别的概率。

3.统计特征，分别统计训练集中按性别、年龄阶段、地区分类的用户所发微博的词汇出现频率，以及发微博的source频率，每个类别抽取top N个词汇和top K个source作为特征字段，统计每个用户所发的微博中出现了多少次高频词和高频source作为特征值，根据微博中的高频词和高频source，统计这些高频词在每个用户的微博和source中出现次数以及这些次数的总和。统计用户在2009-2016年每年发布的帖子，统计0点到23点每小时用户发帖数量。

4.交叉特征，多项式交叉以及相除，然后根据ANOVA、方差等进行特征选择，由于训练集数据规模较小，最终选择了相关性最大的前40个特征。

模型：主要采用gbdt模型（xgboost)，对性别预测使用二分类，对年龄和地点预测使用softmax多分类，线下5fold CV。

模型融合：单独提取文本的tfidf特征，并训练xgboost进行初次预测，将得到的预测结果作为新特征(stacking融合)，和其他特征共同训练xgboost并进行最终的分类预测，最终合并3个分类结果构成最终的提交结果


最终LB成绩：0.695， 排名第五

PS: 代码可以自由使用，但请注明出处。
